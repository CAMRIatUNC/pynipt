{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyNIPT\n",
    "### Version: 0.1.0\n",
    "\n",
    "- The PyNIPT project aims to develop a comprehensive python module for pipeline development for neuroscience data analysis project that comes with a unique project structure that can improve productivity. This module is optimized to work on linux and unix system, but with windows subsystem linux (WSL), it can also be run under particular build of Windows 10.\n",
    "\n",
    "- The project structure is originally designed based on BIDS, which is intuitive for organizing Neuroimaging dataset with meta-data as well as other neurological signal dataset such as EEG. However, BIDS does not provide clear guidlines how to deal with preprocessed data and analyzed results which derived from well-organized original data.\n",
    "\n",
    "- There are several software packages have integrated the BIDS structure, but still, the researcher needs to put extra efforts to organize massive derived data in the case of exploratory approachs, new pipeline development, and optimizing process, which often needs to repeat similar procedure with multiple set of parameters or to test different processing software packages to compare the performances.\n",
    "\n",
    "- Most popular methods to handle derived data are using prefix or suffix on filename, but since the BIDS filename format is already long enough to contains important information, so increasing the complexity of filename severly reduce readibility of dataset.\n",
    "\n",
    "- In this study, we aims to develop comprehansive expension of BIDS to integrate processed data, analyzed results, source code or scripts, as well as the logs generated from each processing steps. The PyNIPT module is designed to help organizing these derived data automatically while performing complex processing steps, statistics, and generating report in python environment. In addition to this, we developed plugin API on Python to implement researchers own pipeline, including debugging tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import PyNIPT module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pynipt as pn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download default plugin\n",
    "- PyNIPT is a pipeline framework and does not contain any hard-coded interface or wrapper to process data. Instead, it can be implemented via plugin\n",
    "- The plugins consist of two python files of Interface and Pipeline, and each plugin is built by single python class structure using API. The interface plugin is designed to contain methods to interace with command-line tool or python function. Both cases, command-line tool and python function, the command must take input and output file path as its arguments. The pipeline plugin is designed to execute a interface plugin with serial manner to form a workflow of data processing, while printing out description of each pipeline step during execution to inform required parameters and which process will be performed. \n",
    "- The plugin will be initially downloaded to '.pynipt' at home folder during installation. But using below python command, it can be re-downloaded or updated. The custom plugin can be imported instead of using the default plugin. We will provide the details on later section of introducing plugin and API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update completed..\n"
     ]
    }
   ],
   "source": [
    "pn.update_default_plugin()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initiate pipeline instance\n",
    "\n",
    "- The proposing project structure consists of four major DataClass, which include naive data, the intermediate data, result, and system logs. The naive data must follow the BIDS standard for the data structure. As default, it locates at the 'Data' folder under the project root. The intermediate data component locates at the 'Processing' folder under the project root, and most of the files created during point to point file processing will be stored at this location while keeping the original data structure. The result component locates at the Results folder under the project root. It is designed to contain interpretable results data, so the statistic results, reports, and results from pear-to-point processing can be stored at this location. \n",
    "- The Pipeline class in PyNIPT module is the major user-interface(UI) that help the researcher to execute pipeline so that all files can be organized as designed manner. It only takes a project root path as an input argument, which contains naive data under 'Data' folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Dataset summary\n",
      "\n",
      "Path of Dataset: /Users/shlee419/Projects/Dataset/SampleDataset/PyNIPT/3Drat_fMRI_2ses\n",
      "Name of Dataset: 3Drat_fMRI_2ses\n",
      "Selected DataClass: Data\n",
      "\n",
      "Subject(s): ['sub-F01', 'sub-F02', 'sub-M01', 'sub-M02']\n",
      "Session(s): ['ses-01', 'ses-02']\n",
      "Datatype(s): ['anat', 'func']\n",
      "Multi session dataset\n",
      "\n",
      "\n",
      "List of installed pipeline packages:\n",
      "\t0 : UNCCH_CAMRI\n"
     ]
    }
   ],
   "source": [
    "pipe = pn.Pipeline('/Users/shlee419/Projects/Dataset/SampleDataset/PyNIPT/3Drat_fMRI_2ses')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Structure of each DataClass.\n",
    "1. 'Data': naive BIDS\n",
    "2. 'Processing': PipelinePackage - StepPath - Subject - (Session) - files\n",
    "3. 'Results': PipelinePackage - StepPath - ReportObj\n",
    "4. 'Logs': DEBUG.log, STDOUT.log, STDERR.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select pipeline package\n",
    "\n",
    "The 'pipeline package' is a package of several pipelines that composed of interface commands. To use Pipeline class, the pipeline package must be specified. Researcher can also create empty pipeline package for developing new pipeline from the scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description about this package:\n",
      "\n",
      "\n",
      "        Standard fMRI pipeline package for the University of North Carolina at Chapel Hill,\n",
      "        to use for the data analysis services in Center of Animal MRI (CAMRI)\n",
      "        Author  : SungHo Lee(shlee@unc.edu)\n",
      "        Revised :\n",
      "            ver.1: Dec.11st.2017\n",
      "            ver.2: Mar.7th.2019\n",
      "\n",
      "        Keyword Args: - listed based on each steps\n",
      "            - 01_EmptyMaskPreparation\n",
      "            anat(str):          datatype for anatomical image (default='anat')\n",
      "            func(str):          datatype for functional image (default='func')\n",
      "            tr(int):            the repetition time of EPI data\n",
      "            tpattern(str):      slice order of image\n",
      "                alt+z = altplus   = alternating in the plus direction\n",
      "                alt+z2            = alternating, starting at slice #1 instead of #0\n",
      "                alt-z = altminus  = alternating in the minus direction\n",
      "                alt-z2            = alternating, starting at slice #nz-2 instead of #nz-1\n",
      "                seq+z = seqplus   = sequential in the plus direction\n",
      "                seq-z = seqminus  = sequential in the minus direction\n",
      "            # Optional for CBV image\n",
      "            cbv_regex(str):     regular expression pattern of filename to select dataset.\n",
      "                                this option can be used when cbv data acquired instead of BOLD,\n",
      "                                because of the negative contrast effect of MION, cbv image is hard to\n",
      "                                register with regular contrasted image. by providing this option to choose\n",
      "                                file's regex pattern of MION infusion data, it will creates average image using\n",
      "                                first 20 frames and last 20 frames to generate BOLD and CBV average images.\n",
      "            cbv_scantime(int):  total scantime for mion infusion image with second.\n",
      "\n",
      "            - 02_CorePreprocessing\n",
      "            template_path(str): absolute path of brain template image (default=None)\n",
      "            aniso(bool):        True if voxel is anisotropic (default=False)\n",
      "                                This option is for the image has truncated brain with thicker slice thickness\n",
      "                                and it uses afni's linear registration for normalization instead ants's non-linear\n",
      "                                registration tool, SyN.\n",
      "\n",
      "            - 03_TaskBased_1stLevelAnalysis\n",
      "            regex(str):             Regular express pattern of filename to select dataset\n",
      "            mask_path(str):         path of brain mask image\n",
      "            fwhm(int or float):     full width half maximum value for smoothing\n",
      "            hrf_model(str):         Hemodynamic Response Function (HRF) according to the 3dDeconvolve command in Afni\n",
      "            hrf_parameters(list):   parameter values for the HRF\n",
      "            stim_onset(list):       stimulation onset times\n",
      "            step_idx(idx):          step_index to classify the step with other when apply multiple\n",
      "            step_tag(str):          suffix tag to classify the step with other when apply multiple\n",
      "\n",
      "            - 04_TaskBased_2ndLevelAnalysis\n",
      "            output_filename(str):   output filename of 2nd level analysis\n",
      "            groupa(str):            datatype or stepcode of input data of group A\n",
      "            groupb(str):            datatype or stepcode of input data of group B\n",
      "            groupa_regex(str):      regular express pattern to filter group A\n",
      "            groupb_regex(str):      regular express pattern to filter group B\n",
      "            clustsim(bool):         use Clustsim option if True\n",
      "            step_idx(idx):          step_index to classify the step with other when apply multiple\n",
      "            step_tag(str):          suffix tag to classify the step with other when apply multiple\n",
      "        \n",
      "The pipeline package 'UNCCH_CAMRI' is selected.\n",
      "Please double check if all parameters are correctly provided before run this pipline\n",
      "List of available pipelines in selected package:\n",
      "\t0 : 01_EmptyMaskPreparation\n",
      "\t1 : 02_CorePreprocessing\n",
      "\t2 : 03_TaskBased_1stLevelAnalysis\n",
      "\t3 : 04_TaskBased_2ndLevelAnalysis\n"
     ]
    }
   ],
   "source": [
    "pipe.set_package(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set parameter and run pipeline\n",
    "\n",
    "- After the pipeline package is selected, it will print out help documents followed by list of availavble pipelines defined in the pipeline plugin. The processing job is performed through the mutltithreading, so while the pipeline running, researcher still can access python interpreter (or jupyter notebook).\n",
    "- The 'check_progression()' method shows current progression of pipeline execution. The progress bar can be updated realtime, so that no additional manual follow-up is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        The dataset will be first slice timing corrected, and average intensity map of functional image\n",
      "        will be calculated on motion corrected data. In the end of this pipeline, empty image file will be\n",
      "        generated in the masking path as a place holder of mask with '_mask' suffix.\n",
      "\n",
      "        If the anatomical data were inputted, the empty mask files will be generated as well.\n",
      "        \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e227e1bf486742b29c64651f2e5b7ed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='UNCCH_CAMRI', max=5.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "UNCCH_CAMRI:   0%|<bar/>| 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe.run(0, tr=2, tpattern='alt+z')\n",
    "pipe.check_progression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calling pipeline instance will show the steps that had been processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "** List of existing steps in selected package [UNCCH_CAMRI]:\n",
       "\n",
       "- Processed steps:\n",
       "\t010: SliceTimingCorrection\n",
       "- Quoue:\n",
       "\t010, 02A, 01A, 01B, 01C"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access backend Paralexe module for debugging\n",
    "- PyNIPT uses Paralexe module as backend processor. Paralexe is a pure python module, stands for 'Parallel Execution', that contains major classes includes Worker, Manager, and Scheduler. As the the name indicates, each class take a role of executing single job, manage the job execution, and schedule job to the thread for the parallel processing.  Accessing this backend tool allows to access the background processor for debuging. Below shows some example of usage of it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'010': Scheduled Job:1::Completed,\n",
       " '02A': Scheduled Job:1::Completed,\n",
       " '01A': Scheduled Job:0::Incompleted,\n",
       " '01B': Scheduled Job:0::Incompleted,\n",
       " '01C': Scheduled Job:0::Incompleted}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.schedulers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "\t** Summery\n",
      "=================================\n",
      "Total number of steps:\t\t1\n",
      "---------------------------------\n",
      "Step::02A\n",
      "\tNumber of workers: \t8\n",
      "---------------------------------\n",
      "Status:\n",
      "\tActive\n",
      "=================================\n"
     ]
    }
   ],
   "source": [
    "pipe.schedulers['02A'].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'010': [Deployed Workers:[8]::Submitted],\n",
       " '02A': [Deployed Workers:[8]::Submitted],\n",
       " '01A': None,\n",
       " '01B': None,\n",
       " '01C': None}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.managers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WorkerID-0\n",
      "  Command: \"3dvolreg -prefix /Users/shlee419/Projects/Dataset/SampleDataset/PyNIPT/3Drat_fMRI_2ses/Processing/UNCCH_CAMRI/02A_MotionCorrection-base/sub-F01/ses-01/sub-F01_ses-01_task-rs_bold.nii.gz -Fourier -verbose -base 0 /Users/shlee419/Projects/Dataset/SampleDataset/PyNIPT/3Drat_fMRI_2ses/Processing/UNCCH_CAMRI/010_SliceTimingCorrection/sub-F01/ses-01/sub-F01_ses-01_task-rs_bold.nii.gz\"\n",
      "  *[ Scheduled job is not executed yet. ]\n",
      "\n",
      "WorkerID-1\n",
      "  Command: \"3dvolreg -prefix /Users/shlee419/Projects/Dataset/SampleDataset/PyNIPT/3Drat_fMRI_2ses/Processing/UNCCH_CAMRI/02A_MotionCorrection-base/sub-F01/ses-02/sub-F01_ses-02_task-rs_bold.nii.gz -Fourier -verbose -base 0 /Users/shlee419/Projects/Dataset/SampleDataset/PyNIPT/3Drat_fMRI_2ses/Processing/UNCCH_CAMRI/010_SliceTimingCorrection/sub-F01/ses-02/sub-F01_ses-02_task-rs_bold.nii.gz\"\n",
      "  *[ Scheduled job is not executed yet. ]\n",
      "\n",
      "WorkerID-2\n",
      "  Command: \"3dvolreg -prefix /Users/shlee419/Projects/Dataset/SampleDataset/PyNIPT/3Drat_fMRI_2ses/Processing/UNCCH_CAMRI/02A_MotionCorrection-base/sub-F02/ses-01/sub-F02_ses-01_task-rs_bold.nii.gz -Fourier -verbose -base 0 /Users/shlee419/Projects/Dataset/SampleDataset/PyNIPT/3Drat_fMRI_2ses/Processing/UNCCH_CAMRI/010_SliceTimingCorrection/sub-F02/ses-01/sub-F02_ses-01_task-rs_bold.nii.gz\"\n",
      "  *[ Scheduled job is not executed yet. ]\n",
      "\n",
      "WorkerID-3\n",
      "  Command: \"3dvolreg -prefix /Users/shlee419/Projects/Dataset/SampleDataset/PyNIPT/3Drat_fMRI_2ses/Processing/UNCCH_CAMRI/02A_MotionCorrection-base/sub-F02/ses-02/sub-F02_ses-02_task-rs_bold.nii.gz -Fourier -verbose -base 0 /Users/shlee419/Projects/Dataset/SampleDataset/PyNIPT/3Drat_fMRI_2ses/Processing/UNCCH_CAMRI/010_SliceTimingCorrection/sub-F02/ses-02/sub-F02_ses-02_task-rs_bold.nii.gz\"\n",
      "  *[ Scheduled job is not executed yet. ]\n",
      "\n",
      "WorkerID-4\n",
      "  Command: \"3dvolreg -prefix /Users/shlee419/Projects/Dataset/SampleDataset/PyNIPT/3Drat_fMRI_2ses/Processing/UNCCH_CAMRI/02A_MotionCorrection-base/sub-M01/ses-01/sub-M01_ses-01_task-rs_bold.nii.gz -Fourier -verbose -base 0 /Users/shlee419/Projects/Dataset/SampleDataset/PyNIPT/3Drat_fMRI_2ses/Processing/UNCCH_CAMRI/010_SliceTimingCorrection/sub-M01/ses-01/sub-M01_ses-01_task-rs_bold.nii.gz\"\n",
      "  *[ Scheduled job is not executed yet. ]\n",
      "\n",
      "WorkerID-5\n",
      "  Command: \"3dvolreg -prefix /Users/shlee419/Projects/Dataset/SampleDataset/PyNIPT/3Drat_fMRI_2ses/Processing/UNCCH_CAMRI/02A_MotionCorrection-base/sub-M01/ses-02/sub-M01_ses-02_task-rs_bold.nii.gz -Fourier -verbose -base 0 /Users/shlee419/Projects/Dataset/SampleDataset/PyNIPT/3Drat_fMRI_2ses/Processing/UNCCH_CAMRI/010_SliceTimingCorrection/sub-M01/ses-02/sub-M01_ses-02_task-rs_bold.nii.gz\"\n",
      "  *[ Scheduled job is not executed yet. ]\n",
      "\n",
      "WorkerID-6\n",
      "  Command: \"3dvolreg -prefix /Users/shlee419/Projects/Dataset/SampleDataset/PyNIPT/3Drat_fMRI_2ses/Processing/UNCCH_CAMRI/02A_MotionCorrection-base/sub-M02/ses-01/sub-M02_ses-01_task-rs_bold.nii.gz -Fourier -verbose -base 0 /Users/shlee419/Projects/Dataset/SampleDataset/PyNIPT/3Drat_fMRI_2ses/Processing/UNCCH_CAMRI/010_SliceTimingCorrection/sub-M02/ses-01/sub-M02_ses-01_task-rs_bold.nii.gz\"\n",
      "  *[ Scheduled job is not executed yet. ]\n",
      "\n",
      "WorkerID-7\n",
      "  Command: \"3dvolreg -prefix /Users/shlee419/Projects/Dataset/SampleDataset/PyNIPT/3Drat_fMRI_2ses/Processing/UNCCH_CAMRI/02A_MotionCorrection-base/sub-M02/ses-02/sub-M02_ses-02_task-rs_bold.nii.gz -Fourier -verbose -base 0 /Users/shlee419/Projects/Dataset/SampleDataset/PyNIPT/3Drat_fMRI_2ses/Processing/UNCCH_CAMRI/010_SliceTimingCorrection/sub-M02/ses-02/sub-M02_ses-02_task-rs_bold.nii.gz\"\n",
      "  *[ Scheduled job is not executed yet. ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe.managers['02A'][0].audit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove the step(s)\n",
    "- If certain processed step is no more needed, it can be removed to restore the storage. It also can be used to re-process the same step with different set of parameters if it required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "List of existing steps in selected package [UNCCH_CAMRI]:\n",
       "\n",
       "- Processed steps:\n",
       "\t010: SliceTimingCorrection\n",
       "\t02A: MotionCorrection-base\n",
       "- Mask data:\n",
       "\t01B: MakeEmptyMask-func\n",
       "\t01C: MakeEmptyMask-anat"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.remove('01A')\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        The dataset will be first slice timing corrected, and average intensity map of functional image\n",
      "        will be calculated on motion corrected data. In the end of this pipeline, empty image file will be\n",
      "        generated in the masking path as a place holder of mask with '_mask' suffix.\n",
      "\n",
      "        If the anatomical data were inputted, the empty mask files will be generated as well.\n",
      "        \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "734d65503b8a4260814723acb854edfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='UNCCH_CAMRI', max=5.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "UNCCH_CAMRI:   0%|<bar/>| 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pipe.run(0)\n",
    "pipe.check_progression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API\n",
    "- InterfaceBuilder: will show how to make command line interface, and python command interface\n",
    "- PipelineBuilder: will show how to make pipeline\n",
    "- Plugin: how to make plugin, and instruction to import new plugin\n",
    "- How to publish your pipeline with PyNIPT (using gist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Dataset summary\n",
      "\n",
      "Path of Dataset: /Users/shlee419/Projects/Dataset/SampleDataset/PyNIPT/3Drat_fMRI_2ses\n",
      "Name of Dataset: 3Drat_fMRI_2ses\n",
      "Selected DataClass: Data\n",
      "\n",
      "Subject(s): ['sub-F01', 'sub-F02', 'sub-M01', 'sub-M02']\n",
      "Session(s): ['ses-01', 'ses-02']\n",
      "Datatype(s): ['anat', 'func']\n",
      "Multi session dataset\n",
      "\n",
      "\n",
      "List of installed pipeline packages:\n",
      "\t0 : UNCCH_CAMRI\n",
      "temporary pipeline package [TEST_PIPELINE] is initiated.\n"
     ]
    }
   ],
   "source": [
    "import pynipt as pn\n",
    "path = '/Users/shlee419/Projects/Dataset/SampleDataset/PyNIPT/3Drat_fMRI_2ses'\n",
    "pipe = pn.Pipeline(path)\n",
    "title = 'TEST_PIPELINE'\n",
    "pipe.set_empty_package(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Example interface for processing command line tools all at once in a dataset (the example below is copying)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itb = pipe.get_builder()\n",
    "itb.init_step('FirstStep', suffix='CMD', \n",
    "              idx=1, subcode=A, mode='processing')\n",
    "itb.set_input(label='input', input_path='func', method=0)\n",
    "itb.set_output(label='output')\n",
    "itb.set_cmd('cp *[input] *[output]')\n",
    "itb.set_output_checker()\n",
    "itb.run()\n",
    "\n",
    "pipe.check_progression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Same as above but python function instead of command line tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d30a30733da4fec8da3ecba2f7c967d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='TEST_PIPELINE', max=1.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TEST_PIPELINE:   0%|<bar/>| 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def sample_func(input, output,               \n",
    "                # the the name of arguments above must be match with user label on interface builder\n",
    "                stdout=None, stderr=None):\n",
    "    import sys\n",
    "    if stdout is None:\n",
    "        stdout = sys.stdout\n",
    "    if stderr is None:\n",
    "        stderr = sys.stderr\n",
    "    \n",
    "    import nibabel as nib\n",
    "    try:\n",
    "        img = nib.load(input)\n",
    "    except Exception as e:\n",
    "        stderr.write(str(e))\n",
    "        return 1\n",
    "    img.to_filename(output)\n",
    "    stdout.write('Copy file from {} to {}'.format(input, output))\n",
    "    return 0\n",
    "\n",
    "itb = pipe.get_builder()\n",
    "itb.init_step('FirstStep', suffix='PYTHON', \n",
    "              idx=1, subcode=0, mode='processing')\n",
    "itb.set_input(label='input', input_path='func', method=0)\n",
    "itb.set_output(label='output')\n",
    "itb.set_func(sample_func)\n",
    "itb.set_output_checker()\n",
    "itb.run(mode='python')\n",
    "\n",
    "pipe.check_progression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "** List of existing steps in selected package [TEST_PIPELINE]:\n",
       "\n",
       "- Processed steps:\n",
       "\t010: FirstStep-200221\n",
       "- Mask data:\n",
       "\t01B: MakeEmptyMask-func\n",
       "\t01C: MakeEmptyMask-anat"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "\t** Summery\n",
      "=================================\n",
      "Total number of steps:\t\t1\n",
      "- Succeeded steps:\t\t1\n",
      "---------------------------------\n",
      "Step::010\n",
      "\tNumber of workers: \t0\n",
      "---------------------------------\n",
      "Status:\n",
      "\tFinished\n",
      "=================================\n"
     ]
    }
   ],
   "source": [
    "pipe.schedulers['010'].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*[ No workers deployed. ]*\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe.managers['010'][0].audit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Dataset summary\n",
      "\n",
      "Path of Dataset: /Users/shlee419/Projects/Dataset/00_SampleDataset/3Drat_fMRI_2ses\n",
      "Name of Dataset: 3Drat_fMRI_2ses\n",
      "Selected DataClass: Data\n",
      "\n",
      "Subject(s): ['sub-F01', 'sub-F02', 'sub-M01', 'sub-M02']\n",
      "Session(s): ['ses-01', 'ses-02']\n",
      "Datatype(s): ['anat', 'func']\n",
      "Multi session dataset\n",
      "\n",
      "\n",
      "List of installed pipeline packages:\n",
      "\t0 : UNCCH_CAMRI\n",
      "temporary pipeline package [TEST_PIPELINE] is initiated.\n"
     ]
    }
   ],
   "source": [
    "import pynipt as pn\n",
    "path = '/Users/shlee419/Projects/Dataset/00_SampleDataset/3Drat_fMRI_2ses'\n",
    "pipe = pn.Pipeline(path)\n",
    "title = 'TEST_PIPELINE'\n",
    "pipe.set_empty_package(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.remove('02A', mode='reporting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "076077bd34a04aeeadba6ddd9f2e6c04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='TEST_PIPELINE', max=2.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TEST_PIPELINE:  50%|<bar/>| 1/2 [00:00<00:00, 36.24it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sample_func2(input, output, test_var,\n",
    "                stdout=None, stderr=None):\n",
    "    import sys\n",
    "    if stdout is None:\n",
    "        stdout = sys.stdout\n",
    "    if stderr is None:\n",
    "        stderr = sys.stderr\n",
    "    \n",
    "    import nibabel as nib\n",
    "    import numpy as np\n",
    "    affine = None\n",
    "    try:\n",
    "        imgobjs = []\n",
    "        for i, img_path in enumerate(input):\n",
    "            stdout.write('{} is loaded'.format(img_path))\n",
    "            img = nib.load(img_path)\n",
    "            if i == 0:\n",
    "                affine = img.affine\n",
    "            if len(img.shape) < 4:\n",
    "                imgobjs.append(np.asarray(img._dataobj)[..., np.newaxis])\n",
    "            else:\n",
    "                imgobjs.append(np.asarray(img._dataobj))\n",
    "    except Exception as e:\n",
    "        stderr.write(str(e))\n",
    "        return 1\n",
    "    \n",
    "    stdout.write('input_var: {}'.format(test_var))\n",
    "    imgobj = np.concatenate(imgobjs, axis=-1)\n",
    "    new_img = nib.Nifti1Image(imgobj, affine)\n",
    "    new_img.to_filename(output)\n",
    "    stdout.write('{} is created'.format(output))\n",
    "    return 0\n",
    "\n",
    "itb = pipe.get_builder()\n",
    "itb.init_step('Reporting', suffix='200226', idx=2, \n",
    "              mode='reporting') # for reporting, as a default, output is directory without extension\n",
    "itb.set_input(label='input', input_path='func', \n",
    "              method=1, # multiple inputs to one output\n",
    "              join_modifier=False) # if this is False, input will return \n",
    "                                   # 'list obj' so can run loop within python function\n",
    "itb.set_output(label='output', \n",
    "               modifier='test', ext='nii.gz') # for peers to one output\n",
    "itb.set_var(label='test_var', value='Hello! World!')\n",
    "itb.set_func(sample_func2)\n",
    "itb.set_output_checker()\n",
    "itb.run(mode='python')\n",
    "pipe.check_progression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = 'copy *[input] *[output]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "** List of existing steps in selected package [TEST_PIPELINE]:\n",
       "\n",
       "- Processed steps:\n",
       "\t010: FirstStep-200221\n",
       "- Reported steps:\n",
       "\t020: Reporting-200226\n",
       "- Quoue:\n",
       "\t020"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'010': Scheduled Job:1::Completed, '020': Scheduled Job:1::Completed}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.schedulers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'010': [Deployed Workers:[8]::Submitted],\n",
       " '020': [Deployed Workers:[1]::Submitted]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.managers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WorkerID-0\n",
      "  Func: \"sample_func2\"\n",
      "  *[ Scheduled job is not executed yet. ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe.managers['020'][0].audit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = pipe.get_dset('020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pipeline</th>\n",
       "      <th>Report</th>\n",
       "      <th>Output</th>\n",
       "      <th>Abspath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_PIPELINE</td>\n",
       "      <td>020_Reporting-200226</td>\n",
       "      <td>test.nii.gz</td>\n",
       "      <td>/Users/shlee419/Projects/Dataset/SampleDataset/PyNIPT/3Drat_fMRI_2ses/Results/TEST_PIPELINE/020_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Pipeline                Report       Output  \\\n",
       "0  TEST_PIPELINE  020_Reporting-200226  test.nii.gz   \n",
       "\n",
       "                                                                                               Abspath  \n",
       "0  /Users/shlee419/Projects/Dataset/SampleDataset/PyNIPT/3Drat_fMRI_2ses/Results/TEST_PIPELINE/020_...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dset.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/shlee419/Projects/Dataset/00_SampleDataset/3Drat_fMRI_2ses/Results/TEST_PIPELINE/02A_Reporting-200226/test.nii.gz\n"
     ]
    }
   ],
   "source": [
    "for i, finfo in dset:\n",
    "    print(finfo.Abspath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}