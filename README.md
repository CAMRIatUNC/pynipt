# PyNIPT (Python NeuroImage Pipeline Tool)
#### Version: 0.2

### Description:
- The PyNIPT module is a pipeline framework for neuroimaging data analysis that offers a convenient, and yet powerful data processing management features under Jupyter Notebook environment. The module is designed to take input from the BIDS dataset and organize the derivates into the block of steps directories instead of using prefix or suffix to modify the filename. Therefore it preserves the original filename during the data processing while the derivates of each pipeline node organized into a single directory. 
- The key features of this module are 
    1. Enabling to execute the command-line interface or python script without input file path specification. The selection of the set of files could be performed via selecting node block and using the regex (regular expression) pattern of the file name.
    2. Continuity of data processing in a single Jupyter notebook session. The module executes the command through background scheduler, so that the Jupyter notebook does not block during data processing.
    3. Providing the API to simplify the development of analysis tools and processing pipeline. The easy-to-use debugging tool also maximizes the convenience of development. 
    
- ***Dependency:***
    - pandas >= 1.0.0 
    - tqdm >= 4.40.0
    - psutil >= 5.5.0
    - paralexe >= 0.1.0
    - shleeh >= 0.0.6

- ***Compatibility:*** 
    - Python > 3.7.5
    - Brain imaging data structure (http://bids.neuroimaging.io)
    - Jupyter notebook environment (https://jupyter.org)

- ***ChangeLog:***
    - v0.2.0 (5/24/2020)    - user interface for debugging
    
### Installation
```js
$ pip install git+https://github.com/pynipt/pynipt
```

### Example Project Data Structure
```python
Project_Root/
├── JupyterNotes/
│   ├── 200514_BrainPacellation.ipynb
│   └── test.nii.gz
├── Data/
│   ├── dataset_description.json
│   ├── README
│   ├── sub-01/
│   │   ├── anat/
│   │   │   ├── sub-01_T2w.json
│   │   │   └── sub-01_T2w.nii.gz
│   │   ├── fmap/
│   │   │   ├── sub-01_fieldmap.json
│   │   │   ├── sub-01_fieldmap.nii.gz
│   │   │   └── sub-01_magnitude.nii.gz
│   │   └── func/
│   │       ├── sub-01_task-rest_bold.json
│   │       └── sub-01_task-rest_bold.nii.gz
│   └── sub-02/
│       ├── anat/
│       │   ├── sub-02_T2w.json
│       │   └── sub-02_T2w.nii.gz
│       ├── fmap/
│       │   ├── sub-02_fieldmap.json
│       │   ├── sub-02_fieldmap.nii.gz
│       │   └── sub-02_magnitude.nii.gz
│       └── func/
│           ├── sub-02_task-rest_bold.json
│           └── sub-02_task-rest_bold.nii.gz
├── Mask/
│   ├── 02A_BrainMaskEstimate-func/
│   │   ├── sub-01/
│   │   │   ├── sub-01_task-rest_bold.nii.gz
│   │   │   └── sub-01_task-rest_bold_mask.nii.gz
│   │   └── sub-02/
│   │       ├── sub-02_task-rest_bold.nii.gz
│   │       └── sub-02_task-rest_bold_mask.nii.gz
│   └── 02B_BrainMaskEstimate-anat/
│       ├── sub-01/
│       │   ├── sub-01_T2w.nii.gz
│       │   └── sub-01_T2w_mask.nii.gz
│       └── sub-02/
│           ├── sub-02_T2w.nii.gz
│           └── sub-02_T2w_mask.nii.gz
├── Processing/
│   └── PipelinePackage/
│       ├── 01A_ProcessingStep1A-func/
│       │   ├── sub-01/
│       │   │   └── sub-01_task-rest_bold.nii.gz
│       │   ├── sub-02/
│       │   │   └── sub-02_task-rest_bold.nii.gz
│       └── 01B_ProcessingStep1B-func/
│           ├── sub-DRRA01F/
│           │   └── sub-01_task-rest_bold.nii.gz
│           └── sub-DRRA01M/
│               └── sub-02_task-rest_bold.nii.gz
├── Results/
│   └── UNCCH_CAMRI/
│       └── 030_2ndLevelStatistic-func/
│           ├── TTest.nii.gz
│           └── TTest_report.html
├── Temp/
├── Logs/
│   ├── DEBUG.log
│   ├── STDERR.log
│   └── STDOUT.log
└── Template/
    └── BrainTemplate.nii.gz
```
#### It is composed of 6 data components under project folder
- **Data**: naive BIDS dataset
- **Mask**: the file to store single subject-level image segmentation such as brain mask    
- **Processing**: the intermediate files that generated by this module, it could be used as input for later processing nodes.
- **Results**: the report files that does not preserve original data structure, such as group-level analysis.
- **Temp**: the intermediate file that can be disposed without worry. (which means not important to keep for the further process)
- **Log**: the central location to store the log files for debugging messages, standard output and error messages from sub-processes.

#### Optional data components
- **JupyterNotes**: to store Jupyter notebook for documenting and visualizing your overall data process and analysis.
- **Templates**: to store anatomical template, group level brain masks, and labelled brain atlas.

### Data filtering
#### Regular expression for data filtering
- Regex patterns using in this module
    - This module use regular expression to search specific filename without extension, 
    so the file extension must be provided as separate filter key.
- Filter key
    - Dataclass specific keys
        - dataset path (idx:0): subjects, datatypes
        - working path (idx:1): pipelines, steps
        - results path (idx:2): pipelines, reports
        - masking path (idx:3): subjects, datatypes
        - temporary    (idx:4): pipelines, steps
    - File specific keys
        - regex: regex pattern for filename
        - ext: file extension
        
- Output filename specification
    - Using prefix, suffix, and/or modifier will result in the change of output filename. 
    - The modifier is the key-value paired python dictionary object. the value in key will be searched and will be replaced to the string in value.
    - Or in case of reporting purpose (which the group_input=1), single string can be use as output filename

- Output checker
    - The output checker required to validate if the result file is generated.
    - If the output filename is same as the one you specified in output, you only need to input the label of your output.
    - However, some tools generate multiple files which result in modifying filename.
    - In this case, you can specify the prefix and suffix here to let the processor knows what file you want to check to validate the success of process.

### The StepCode to access data
- Step code is designed to enhance data accessibility of specific processing node without knowing the data structure.
- In PyNIPT, each processing step required to assign unique StepCode composed of 3 characters. (e.g. '03E')
    - The first two integers are to identify 'the level of process'. Total 100 levels (00 to 99) are available.
    - The last one character is to identify 'the sub-step of each level'. Total 27 sub-step can be specified (0 or A-Z)
    - The sub-step can be used 
- Example folder name of one processing node: '01E_MotionCorrection-func'
    - The '01E' is StepCode
    - The 'MotionCorrection' is the title of processing node
    - The 'func' is the suffix for distinguish the node if the same processing node is used multiple time. (the same folder is not allowed to use multiple time, so using suffix is crucial.)

### Tutorials
*The tutorial does not ready yet, will be provided soon*
- Getting started
    - How to access the data
    - Processing node
    - Pipeline
    - Debugging
- Development
    - Interface and pipeline plugin
    - packaging your plugin
    
#### License

PyNIPT is licensed under the term of the GNU GENERAL PUBLIC LICENSE Version 3

#### Authors

The main author of **PyNIT project** is SungHo Lee (shlee@unc.edu). Please join us if you want to contribute this project.

#### Contributors
